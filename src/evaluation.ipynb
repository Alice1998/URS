{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_list=['Solve_Professional_Problem','Factual_QA','API','Text_Assistant','Seek_Creativity','Ask_for_Advice','Leisure']\n",
    "field=field_list[1]\n",
    "test_model_list=['deepseek-chat','gpt-3.5-turbo','glm-4','Baichuan2-Turbo','spark-3.5','qwen-max','gpt-4-0125-preview','ERNIE-Bot-4']\n",
    "test_model=test_model_list[-2]\n",
    "df=pd.read_csv(f'../data/evaluation/{field}_{test_model}_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 首先匹配大括号内的所有内容\n",
    "\n",
    "tag_dict={\"Solve_Professional_Problem\":['事实正确性','满足用户需求','清晰度','逻辑连贯性','完备性','综合得分'],\\\n",
    "        \"Factual_QA\":['事实正确性','满足用户需求','清晰度','完备性','逻辑连贯性','综合得分'],\\\n",
    "        'API':['事实正确性','满足用户需求','清晰度','逻辑连贯性','完备性','综合得分'],\\\n",
    "        'Seek_Creativity':['满足用户需求','逻辑连贯性','创造性','丰富度','事实正确性','综合得分'],\\\n",
    "        'Ask_for_Advice':['满足用户需求','事实正确性','公平与可负责程度','创造性','丰富度','综合得分'],\\\n",
    "        'Leisure':['满足用户需求','趣味性','适宜性','创造性','事实正确性','综合得分'],\\\n",
    "        'Text Assistant':['清晰度','满足用户需求','逻辑连贯性','事实正确性','创造性','综合得分']\n",
    "        }\n",
    "tag_list=tag_dict[field]\n",
    "\n",
    "def extract_data(test_str):\n",
    "    pattern_general = r'\\{[^}]+\\}'\n",
    "    # 使用正则表达式搜索\n",
    "    # general_match = re.search(pattern_general, test_str)\n",
    "    general_match = re.findall(pattern_general, test_str)\n",
    "\n",
    "    # 如果找到匹配项，进一步处理\n",
    "    if general_match:\n",
    "        # matched_str = general_match.group(0)\n",
    "        matched_str=general_match[-1]\n",
    "\n",
    "        # 构建一个新的正则表达式来匹配每个字段及其值\n",
    "        pattern_fields = '|'.join([f'(?:\\'|\\\"|’|‘)?{re.escape(tag)}(?:\\'|\\\"|’|‘)?\\s*:\\s*(\\d+)' for tag in tag_list])\n",
    "\n",
    "        # 查找所有匹配的字段和值\n",
    "        fields_matches = re.findall(pattern_fields, matched_str)\n",
    "\n",
    "        # 将匹配到的字段和值转换为字典\n",
    "        result_dict = {}\n",
    "        for i, tag in enumerate(tag_list):\n",
    "            for match in fields_matches:\n",
    "                if match[i]:\n",
    "                    result_dict[tag] = int(match[i])\n",
    "                    break\n",
    "        if len(result_dict)!=6:\n",
    "            print(\"ERROR! type 1\")\n",
    "            print(result_dict)\n",
    "            print(test_str)\n",
    "    else:\n",
    "        result_dict = {}\n",
    "        print(\"ERROR! type 2\")\n",
    "        print(test_str)\n",
    "\n",
    "    # 输出结果\n",
    "    # print(result_dict)\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! type 1\n",
      "{'清晰度': 9, '逻辑连贯性': 9, '完备性': 8, '综合得分': 9}\n",
      "对比参考答案，AI助手的回答在结构和内容上有所扩展，补充了一些关于规划爬虫、处理反爬虫策略和测试部署的步骤。然而，在部分区域也存在不足之处。\n",
      "\n",
      "1. **事实正确性(Factuality):** AI助手的回答中提供的信息是准确的，涵盖了从环境准备到最终部署的全过程，并正确说明了使用Python开发网页爬虫需要考虑的要素。没有发现明显的事实错误。打分：9\n",
      "\n",
      "2. **满足用户需求(User Satisfaction):** 回答补充了一些参考答案中没有覆盖的领域，如反爬策略和爬虫测试、部署，从某种角度来说，有助于提高用户在网页爬虫开发过程中的整体理解。然而，对于某些步骤的细节，如“使用代理IP、设置适当的下载延时等”对抗反爬虫策略，缺乏具体示例或进一步的解释，可能会留给用户一些疑问。打分：8\n",
      "\n",
      "3. **清晰度(Clarity):** AI助手的回答结构清晰，使用了标题和编号列出开发步骤。语言使用简洁，容易理解。打分：9\n",
      "\n",
      "4. **逻辑连贯性(Logical Coherence):** 回答整体上逻辑连贯，步骤顺序合理，从准备环境到部署测试，逐步引导，每一步都建立在前一步的基础上。打分：9\n",
      "\n",
      "5. **完备性(Completeness):** 除了在反爬策略的具体执行手段上留给用户一些空间外，AI助手提供了一个比较全面的网页爬虫开发指南。与参考答案相比，AI助手的回答在一些方面提供了更多的信息和建议，增加了内容的完备性。打分：8\n",
      "\n",
      "根据上述评价，AI助手的回答在几个重要的维度上表现出色，特别是在事实正确性和逻辑连贯性方面。尽管在完备性维度上略显不足，但整体而言，其质量与参考答案相近，可以视为对用户问题的充分解决。\n",
      "\n",
      "综合得分：{’维度一’: 9, ’维度二’: 8, ’清晰度’: 9, ’逻辑连贯性’: 9, ’完备性’: 8, ’综合得分’: 9}\n"
     ]
    }
   ],
   "source": [
    "for index,row in df.iterrows():\n",
    "    test_str=row['evaluation']\n",
    "    ans_dict=extract_data(test_str)\n",
    "    for key in ans_dict:\n",
    "        df.loc[index,key]=ans_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'q1', 'GPT4-ans', 'gpt-3.5-turbo', 'evaluation', '事实正确性', '满足用户需求', '清晰度', '逻辑连贯性', '完备性', '综合得分']\n",
      "['事实正确性', '满足用户需求', '清晰度', '逻辑连贯性', '完备性', '综合得分', 'q1', 'GPT4-ans', 'gpt-3.5-turbo', 'evaluation']\n"
     ]
    }
   ],
   "source": [
    "col_list=df.columns.tolist()\n",
    "print(col_list)\n",
    "df[col_list].to_csv(f'../data/final_evaluation/Final-{field}-{test_model}-eval.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm-4\n",
      "gpt-3.5-turbo\n",
      "deepseek-chat\n",
      "spark-3.5\n",
      "Baichuan2-Turbo\n",
      "qwen-max\n",
      "gpt-4-0125-preview\n",
      "ERNIE-Bot-4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>glm-4</th>\n",
       "      <td>7.34158</td>\n",
       "      <td>1.65333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>6.55446</td>\n",
       "      <td>1.45565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-chat</th>\n",
       "      <td>6.91584</td>\n",
       "      <td>1.44823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spark-3.5</th>\n",
       "      <td>6.77228</td>\n",
       "      <td>1.5153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baichuan2-Turbo</th>\n",
       "      <td>6.61386</td>\n",
       "      <td>1.4726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qwen-max</th>\n",
       "      <td>7.27723</td>\n",
       "      <td>1.1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-0125-preview</th>\n",
       "      <td>7.9901</td>\n",
       "      <td>0.982383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERNIE-Bot-4</th>\n",
       "      <td>7.25248</td>\n",
       "      <td>1.14197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean       std\n",
       "glm-4               7.34158   1.65333\n",
       "gpt-3.5-turbo       6.55446   1.45565\n",
       "deepseek-chat       6.91584   1.44823\n",
       "spark-3.5           6.77228    1.5153\n",
       "Baichuan2-Turbo     6.61386    1.4726\n",
       "qwen-max            7.27723    1.1296\n",
       "gpt-4-0125-preview   7.9901  0.982383\n",
       "ERNIE-Bot-4         7.25248   1.14197"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "model_list=['glm-4','gpt-3.5-turbo','deepseek-chat','spark-3.5','Baichuan2-Turbo','qwen-max','gpt-4-0125-preview','ERNIE-Bot-4']\n",
    "field_list=['Solve_Professional_Problem','Factual_QA','API','Text_Assistant','Seek_Creativity','Ask_for_Advice','Leisure']\n",
    "# field_list=['SolveProblem','API','SeekCreativity','Advice','Leisure']\n",
    "test_list=model_list\n",
    "other=field_list[1]\n",
    "ans_df=pd.DataFrame(index=test_list,columns=['mean','std'])\n",
    "\n",
    "for test in test_list:\n",
    "    model=test\n",
    "    field=other\n",
    "    df=pd.read_csv(f'../data/final_evaluation/Final-{field}-{model}-eval.csv')\n",
    "    # print(model)\n",
    "    # print(df.describe())\n",
    "    print(test)\n",
    "    # print(df.columns)\n",
    "    ans_df.loc[test,'mean']=df['综合得分'].mean()\n",
    "    ans_df.loc[test,'std']=df['综合得分'].std()\n",
    "ans_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
